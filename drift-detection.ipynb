{
 "cells": [
  {
   "attachments": {
    "ibm-logo-bw.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Drift detection\n",
    "\n",
    "![ibm-logo-bw.png](attachment:ibm-logo-bw.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import joblib\n",
    "import uuid\n",
    "from collections import Counter,defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from termcolor import cprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "MODEL_VERSION = \"0.1\"\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 11\n",
    "LARGE_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=LARGE_SIZE)   # fontsize of the figure title\n",
    "\n",
    "def slide_print(text, color='white'):\n",
    "    cprint(text, color, 'on_grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are many methods that can be used to detect performance drift.  We have already learned about novelty detection \n",
    "and outlier detection algorithms so we will demonstrate drift detection using these methods.  We will also include a test using a distance metric to help detect distributional changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<table class=\"chTable\" style=\"width:45%\">\n",
    "  <tr>\n",
    "      <td>Outlier detection</td>\n",
    "      <td>Outliers are defined from the training data</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td><br>Novelty detection</br></td>\n",
    "      <td>Process assumes that the training data does not contain outliers</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "Main applications:\n",
    "\n",
    "* Supervised learning for extremely imbalanced data\n",
    "* Outlier/novelty detection for deployed models\n",
    "* Quality assurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "As a reminder outlier detection is distinguished from novelty detection by the whether or not outliers are assumed to be present in the training data.  If you think about it a little these methods have other uses beyond drift.  For example maybe you have say a deployed classification model and you would like to monitor for aberrant predictions.   You could also monitor the input data for a given model, by asking if it is similiar to historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Performance Drift\n",
    "\n",
    "> Any appreciable change in model performance between null and test data sets\n",
    "\n",
    "* <span style=\"color:orange\">concept drift</span> - the statistical distribution of a target variable changes over time\n",
    "* <span style=\"color:orange\">software decay</span> - phrase used to describe a model that decreases in performance \n",
    "* <span style=\"color:orange\">sampling bias</span> - sample is collected in such a way that some members of the intended population have a lower sampling probability than others\n",
    "\n",
    "We will use the iris data to generate batches of data in a way that simulates a form of sampling bias, which will cause concept drift.  We will monitor the predictions with log files and a novelty detection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "If we define performance drift as \"any appreciable change in model performance between null and test data sets\".  The null data set can be defined in many ways.  It could be all historical data, it could be all of the previous years data or just the data from the most recent training batch.  The null distribution in this case will depend on the business opportunity. One form of performance drift is known as concept drift and it is where the statistical distribution of the target variable changes over time.  We will use the iris data to generate batches of data in a way that simulates a form of sampling bias, which will cause concept drift.  This is not the only possible form of sampling bias to be aware of as there could be under represented groups within a data set that are not directly related to the target variable.  For this example, we will use the class proportions in the target variable to demonstrate drifting model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of the functions for this example\n",
    "\n",
    "We are going to use the functions from `example-logging.py` to demonstrate one technique for performance monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## note functions are bundled here to keep the demo portable, but source code should exist in separate files\n",
    "\n",
    "def train_model(X, y, saved_model):\n",
    "    \"\"\"\n",
    "    function to train model\n",
    "    \"\"\"\n",
    "\n",
    "    slide_print(\"... training\")\n",
    "    \n",
    "    ## Perform a train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    ## Specify parameters and model\n",
    "    params = {'C':1.0, 'kernel':'linear', 'gamma':0.5}\n",
    "    clf = svm.SVC(**params, probability=True)\n",
    "\n",
    "    ## fit model on training data\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    slide_print(classification_report(y_test, y_pred))\n",
    "\n",
    "    ## retrain using all data\n",
    "    clf.fit(X, y)\n",
    "    joblib.dump(clf, saved_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Lets quickly look at the functions that we will use for this demonstration.  The train_model function is very similar to other train functions that we have seen.  We are not logging any data associated with the training at this point, but in a normal production scenario you would keep track of runtime,  model version and a summary of the classification report at a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def predict(query, saved_model, verbose=True):\n",
    "    \"\"\"\n",
    "    generic function for prediction\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        slide_print(\"... predicting\")\n",
    "    \n",
    "    ## start timer for runtime\n",
    "    time_start = time.time()\n",
    "    \n",
    "    ## ensure the model is loaded\n",
    "    model = joblib.load(saved_model)\n",
    "\n",
    "    ## input checks\n",
    "    if isinstance(query,list):\n",
    "        query = np.array([query])\n",
    "    if len(query.shape) == 1:\n",
    "        query = query.reshape(1, -1)\n",
    "    \n",
    "    ## make prediction and gather data for log entry\n",
    "    y_pred = model.predict(query)\n",
    "    y_proba = None\n",
    "    if 'predict_proba' in dir(model) and model.probability == True:\n",
    "        y_proba = model.predict_proba(query)\n",
    "    m, s = divmod(time.time()-time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "\n",
    "    ## update the log file\n",
    "    _update_predict_log(y_pred, y_proba, query, runtime)\n",
    "    \n",
    "    return(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The predict function we are using. It is minimal implementation in terms of how hardened it is to different inputs. For example, we could add checks for the correct number and format of individual features, but this is enough to showcase the general process of detecting drift.  We are logging the predictions the probabilities associated with the predictions, the query itself and the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def _update_predict_log(y_pred, y_proba, query, runtime):\n",
    "    \"\"\"\n",
    "    update predict log file\n",
    "    \"\"\"\n",
    "    \n",
    "    ## name the logfile using something that cycles with date (day, month, year)    \n",
    "    today = date.today()\n",
    "    logfile = \"iris-svm-{}-{}.log\".format(today.year, today.month)\n",
    "\n",
    "    ## write the data to a csv file    \n",
    "    header = ['unique_id', 'timestamp', 'y_pred', 'y_proba', 'x_shape', 'model_version', 'runtime']\n",
    "    write_header = False\n",
    "    if not os.path.exists(logfile):\n",
    "        write_header = True\n",
    "    with open(logfile, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='|')\n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "\n",
    "        to_write = map(str, [uuid.uuid4(), time.time(), y_pred, y_proba, query.shape, MODEL_VERSION, runtime])\n",
    "        writer.writerow(to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is the function to write to a log file.  This function could be bundled with other helper functions as a class or python module, but for at a minimum.  Given the row entries the file is opened using the append mode and they are written along with a unique id time_stamp and model version. We hardcoded the model version at the top of this notebook to keep the example concise, but generally it would reside in the `model.py` file or something similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[40m\u001B[37m... training\u001B[0m\n",
      "\u001B[40m\u001B[37m              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.67      0.53      0.59        15\n",
      "           2       0.63      0.75      0.69        16\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.77      0.76      0.76        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\u001B[0m\n",
      "\u001B[40m\u001B[37m... predicting\u001B[0m\n",
      "\u001B[40m\u001B[37m... predicting\u001B[0m\n",
      "\u001B[40m\u001B[37m... predicting\u001B[0m\n",
      "\u001B[40m\u001B[37mpredicted: [1, 2, 0]\u001B[0m\n",
      "\u001B[40m\u001B[37m1.0\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "## import the original iris data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,:2]\n",
    "y = iris.target\n",
    "\n",
    "## remove existing log file to start clean\n",
    "today = date.today()\n",
    "logfile = \"iris-svm-{}-{}.log\".format(today.year, today.month)\n",
    "if os.path.exists(logfile):\n",
    "    os.remove(logfile)\n",
    "\n",
    "## train the model\n",
    "saved_model = \"iris-svm-{}.joblib\".format(re.sub(\"\\.\", \"_\", str(MODEL_VERSION)))\n",
    "train_model(X, y, saved_model)\n",
    "\n",
    "## example predict\n",
    "queries = [[6.1, 2.8], [7.7, 2.5], [5.8, 3.8]]\n",
    "y_pred = [predict(query, saved_model)[0] for query in queries]\n",
    "slide_print(\"predicted: {}\".format(y_pred))\n",
    "slide_print(f1_score([1,2,0], y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This slide shows the functions in use.  First we load the iris data limiting it to only the first two features.  With all of the features the classification problem becomes too easy and makes the demonstration unrealistic.  We show how to train the model and run a query.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Simulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[40m\u001B[37m[(0, 50), (1, 50), (2, 50)]\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "slide_print(sorted(Counter(y).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[40m\u001B[37m[(0, 38), (1, 38), (2, 75)]\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "def simulate_samples(nsamples, X, y, weights):\n",
    "    \"\"\"\n",
    "    simulate new samples (via bootstrap) varying the relative percentages\n",
    "    ensure the weights sum to 1.0\n",
    "    \"\"\"\n",
    "\n",
    "    totals = np.round(np.array(weights) * nsamples).astype(int)\n",
    "    indices = np.arange(y.size)\n",
    "    new_indices = []\n",
    "    for i, c in enumerate(np.unique(y)):\n",
    "        new_indices.extend(np.random.choice(indices[y==c], totals[i], replace=True))\n",
    "     \n",
    "    y_new = y[new_indices]\n",
    "    X_new = X[new_indices,:]\n",
    "    return(X_new, y_new)\n",
    "\n",
    "n = 150\n",
    "weights = np.array([0.25, 0.25, 0.50]) \n",
    "X_new, y_new = simulate_samples(n, X, y, weights)\n",
    "slide_print(sorted(Counter(y_new).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here we have a function to simulate new samples using the bootstrap, which as a reminder is sampling with replacement.  We see the original data has balanced classes as shown with the Counter dictionary.  We then run the simulate_samples function to see how the data change. (Optionally change n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[40m\u001B[37mpercent class 3: 0.33, f1_score: 0.8\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.38, f1_score: 0.79\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.43, f1_score: 0.77\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.48, f1_score: 0.78\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.52, f1_score: 0.78\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.58, f1_score: 0.77\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.64, f1_score: 0.74\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.68, f1_score: 0.75\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.72, f1_score: 0.79\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.78, f1_score: 0.73\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.84, f1_score: 0.82\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.88, f1_score: 0.72\u001B[0m\n",
      "\u001B[40m\u001B[37mpercent class 3: 0.92, f1_score: 0.81\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "drifting_weights = [np.array([(100-p)/2.0, (100-p)/2.0, p]) / 100.0 for p in np.arange(33, 95, 5)]\n",
    "n = 100\n",
    "for weights in drifting_weights:\n",
    "    X_new, y_new = simulate_samples(n, X, y, weights)\n",
    "    percent_class_3 = np.round(y_new[y_new==2].size / y_new.size, 2)\n",
    "    y_pred = [predict(X_new[row,:], saved_model, verbose=False)[0] for row in range(y_new.shape[0])]\n",
    "    f1 = np.round(f1_score(y_new, y_pred, average='weighted'), 2)\n",
    "    slide_print(\"percent class 3: {}, f1_score: {}\".format(percent_class_3, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here we simulate a bunch of data where the percentage of class three is taking up more an more of the overall feature space.  The percentage ranges from 33 percent up until 92.  Recall that the original f_1 score was 0.78. so that means that our model performance stayed roughly the same with maybe even a small increase in performance.  This implies that if we were monitoring based on f1_score along we would potentially miss out on the fact that we have very imbalanced classes now.  SVMs if you recall can do quite well with class imbalance.  We were only able to calculate the f1_scores because we know the true predictions.  This would  analogous to waiting until the query data was labeled and then coming back and checking whether or not the model performance is drifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "clf_y = EllipticEnvelope(random_state=0, contamination=0.01)\n",
    "clf_X = EllipticEnvelope(random_state=0, contamination=0.01)\n",
    "\n",
    "clf_X.fit(X)\n",
    "clf_y.fit(y.reshape(y.size, 1))\n",
    "\n",
    "results = defaultdict(list)\n",
    "for weights in drifting_weights:\n",
    "    X_new,y_new = simulate_samples(n, X, y, weights)\n",
    "    results[\"class_3_percent\"].append(np.round(y_new[y_new==2].size / y_new.size, 2))\n",
    "    results['wasserstein_X'].append(np.round(wasserstein_distance(X.flatten(), X_new.flatten()), 2))\n",
    "    results['wasserstein_y'].append(np.round(wasserstein_distance(y, y_new), 2))\n",
    "    test1 = clf_X.predict(X_new)\n",
    "    test2 = clf_y.predict(y_new.reshape(y_new.size, 1))\n",
    "    results[\"outlier_percent_X\"].append(np.round(1.0 - (test1[test1==1].size / test1.size), 2))\n",
    "    results[\"outlier_percent_y\"].append(np.round(1.0 - (test2[test2==1].size / test2.size), 2))\n",
    "    \n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "There was a major shift in the distributional nature of our data. Given the such an extreme change in our data we would want to know about it even if it is not readily apparent in by looking at the logged evaluation metric.  So here we are testing for outliers, using the Elliptic Envelop, a variance based method. It is important to note that we are looking for outliers not distributional changes, which can be related, but they do not necessarily coincide.  To specifically look for distributional changes we also use the Wasserstein metric.  We run both of these checks on the features and on the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_a3568_row0_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 55.7%, transparent 55.7%);\n",
       "        }#T_a3568_row0_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 50.6%, transparent 50.6%);\n",
       "        }#T_a3568_row0_col3{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, red 50.0%, red 65.0%, transparent 65.0%);\n",
       "        }#T_a3568_row0_col4,#T_a3568_row1_col3,#T_a3568_row1_col4,#T_a3568_row2_col4,#T_a3568_row3_col4,#T_a3568_row4_col3,#T_a3568_row4_col4,#T_a3568_row5_col4,#T_a3568_row6_col4,#T_a3568_row7_col4,#T_a3568_row8_col3,#T_a3568_row8_col4,#T_a3568_row9_col3,#T_a3568_row9_col4,#T_a3568_row10_col4,#T_a3568_row11_col3,#T_a3568_row11_col4,#T_a3568_row12_col3,#T_a3568_row12_col4{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }#T_a3568_row1_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 58.0%, transparent 58.0%);\n",
       "        }#T_a3568_row1_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 54.0%, transparent 54.0%);\n",
       "        }#T_a3568_row2_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 61.4%, transparent 61.4%);\n",
       "        }#T_a3568_row2_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 58.5%, transparent 58.5%);\n",
       "        }#T_a3568_row2_col3,#T_a3568_row3_col3,#T_a3568_row5_col3,#T_a3568_row6_col3,#T_a3568_row7_col3{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, red 50.0%, red 60.0%, transparent 60.0%);\n",
       "        }#T_a3568_row3_col1,#T_a3568_row4_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 64.8%, transparent 64.8%);\n",
       "        }#T_a3568_row3_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 62.5%, transparent 62.5%);\n",
       "        }#T_a3568_row4_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 66.5%, transparent 66.5%);\n",
       "        }#T_a3568_row5_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 70.5%, transparent 70.5%);\n",
       "        }#T_a3568_row5_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 71.0%, transparent 71.0%);\n",
       "        }#T_a3568_row6_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 75.0%, transparent 75.0%);\n",
       "        }#T_a3568_row6_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 75.6%, transparent 75.6%);\n",
       "        }#T_a3568_row7_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 73.9%, transparent 73.9%);\n",
       "        }#T_a3568_row7_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 79.5%, transparent 79.5%);\n",
       "        }#T_a3568_row8_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 80.7%, transparent 80.7%);\n",
       "        }#T_a3568_row8_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 83.0%, transparent 83.0%);\n",
       "        }#T_a3568_row9_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 85.2%, transparent 85.2%);\n",
       "        }#T_a3568_row9_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 88.1%, transparent 88.1%);\n",
       "        }#T_a3568_row10_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 86.4%, transparent 86.4%);\n",
       "        }#T_a3568_row10_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 93.2%, transparent 93.2%);\n",
       "        }#T_a3568_row10_col3{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, red 50.0%, red 55.0%, transparent 55.0%);\n",
       "        }#T_a3568_row11_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 92.0%, transparent 92.0%);\n",
       "        }#T_a3568_row11_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 96.6%, transparent 96.6%);\n",
       "        }#T_a3568_row12_col1,#T_a3568_row12_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 100.0%, transparent 100.0%);\n",
       "        }</style><table id=\"T_a3568_\" ><caption>Performance Monitoring</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >class_3_percent</th>        <th class=\"col_heading level0 col1\" >wasserstein_X</th>        <th class=\"col_heading level0 col2\" >wasserstein_y</th>        <th class=\"col_heading level0 col3\" >outlier_percent_X</th>        <th class=\"col_heading level0 col4\" >outlier_percent_y</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_a3568_row0_col0\" class=\"data row0 col0\" >0.330000</td>\n",
       "                        <td id=\"T_a3568_row0_col1\" class=\"data row0 col1\" >0.050000</td>\n",
       "                        <td id=\"T_a3568_row0_col2\" class=\"data row0 col2\" >0.010000</td>\n",
       "                        <td id=\"T_a3568_row0_col3\" class=\"data row0 col3\" >0.030000</td>\n",
       "                        <td id=\"T_a3568_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row1_col0\" class=\"data row1 col0\" >0.380000</td>\n",
       "                        <td id=\"T_a3568_row1_col1\" class=\"data row1 col1\" >0.070000</td>\n",
       "                        <td id=\"T_a3568_row1_col2\" class=\"data row1 col2\" >0.070000</td>\n",
       "                        <td id=\"T_a3568_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "                        <td id=\"T_a3568_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row2_col0\" class=\"data row2 col0\" >0.430000</td>\n",
       "                        <td id=\"T_a3568_row2_col1\" class=\"data row2 col1\" >0.100000</td>\n",
       "                        <td id=\"T_a3568_row2_col2\" class=\"data row2 col2\" >0.150000</td>\n",
       "                        <td id=\"T_a3568_row2_col3\" class=\"data row2 col3\" >0.020000</td>\n",
       "                        <td id=\"T_a3568_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row3_col0\" class=\"data row3 col0\" >0.480000</td>\n",
       "                        <td id=\"T_a3568_row3_col1\" class=\"data row3 col1\" >0.130000</td>\n",
       "                        <td id=\"T_a3568_row3_col2\" class=\"data row3 col2\" >0.220000</td>\n",
       "                        <td id=\"T_a3568_row3_col3\" class=\"data row3 col3\" >0.020000</td>\n",
       "                        <td id=\"T_a3568_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row4_col0\" class=\"data row4 col0\" >0.520000</td>\n",
       "                        <td id=\"T_a3568_row4_col1\" class=\"data row4 col1\" >0.130000</td>\n",
       "                        <td id=\"T_a3568_row4_col2\" class=\"data row4 col2\" >0.290000</td>\n",
       "                        <td id=\"T_a3568_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "                        <td id=\"T_a3568_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row5_col0\" class=\"data row5 col0\" >0.580000</td>\n",
       "                        <td id=\"T_a3568_row5_col1\" class=\"data row5 col1\" >0.180000</td>\n",
       "                        <td id=\"T_a3568_row5_col2\" class=\"data row5 col2\" >0.370000</td>\n",
       "                        <td id=\"T_a3568_row5_col3\" class=\"data row5 col3\" >0.020000</td>\n",
       "                        <td id=\"T_a3568_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row6_col0\" class=\"data row6 col0\" >0.640000</td>\n",
       "                        <td id=\"T_a3568_row6_col1\" class=\"data row6 col1\" >0.220000</td>\n",
       "                        <td id=\"T_a3568_row6_col2\" class=\"data row6 col2\" >0.450000</td>\n",
       "                        <td id=\"T_a3568_row6_col3\" class=\"data row6 col3\" >0.020000</td>\n",
       "                        <td id=\"T_a3568_row6_col4\" class=\"data row6 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row7_col0\" class=\"data row7 col0\" >0.680000</td>\n",
       "                        <td id=\"T_a3568_row7_col1\" class=\"data row7 col1\" >0.210000</td>\n",
       "                        <td id=\"T_a3568_row7_col2\" class=\"data row7 col2\" >0.520000</td>\n",
       "                        <td id=\"T_a3568_row7_col3\" class=\"data row7 col3\" >0.020000</td>\n",
       "                        <td id=\"T_a3568_row7_col4\" class=\"data row7 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row8_col0\" class=\"data row8 col0\" >0.720000</td>\n",
       "                        <td id=\"T_a3568_row8_col1\" class=\"data row8 col1\" >0.270000</td>\n",
       "                        <td id=\"T_a3568_row8_col2\" class=\"data row8 col2\" >0.580000</td>\n",
       "                        <td id=\"T_a3568_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "                        <td id=\"T_a3568_row8_col4\" class=\"data row8 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row9_col0\" class=\"data row9 col0\" >0.780000</td>\n",
       "                        <td id=\"T_a3568_row9_col1\" class=\"data row9 col1\" >0.310000</td>\n",
       "                        <td id=\"T_a3568_row9_col2\" class=\"data row9 col2\" >0.670000</td>\n",
       "                        <td id=\"T_a3568_row9_col3\" class=\"data row9 col3\" >0.000000</td>\n",
       "                        <td id=\"T_a3568_row9_col4\" class=\"data row9 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row10_col0\" class=\"data row10 col0\" >0.840000</td>\n",
       "                        <td id=\"T_a3568_row10_col1\" class=\"data row10 col1\" >0.320000</td>\n",
       "                        <td id=\"T_a3568_row10_col2\" class=\"data row10 col2\" >0.760000</td>\n",
       "                        <td id=\"T_a3568_row10_col3\" class=\"data row10 col3\" >0.010000</td>\n",
       "                        <td id=\"T_a3568_row10_col4\" class=\"data row10 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row11_col0\" class=\"data row11 col0\" >0.880000</td>\n",
       "                        <td id=\"T_a3568_row11_col1\" class=\"data row11 col1\" >0.370000</td>\n",
       "                        <td id=\"T_a3568_row11_col2\" class=\"data row11 col2\" >0.820000</td>\n",
       "                        <td id=\"T_a3568_row11_col3\" class=\"data row11 col3\" >0.000000</td>\n",
       "                        <td id=\"T_a3568_row11_col4\" class=\"data row11 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a3568_row12_col0\" class=\"data row12 col0\" >0.920000</td>\n",
       "                        <td id=\"T_a3568_row12_col1\" class=\"data row12 col1\" >0.440000</td>\n",
       "                        <td id=\"T_a3568_row12_col2\" class=\"data row12 col2\" >0.880000</td>\n",
       "                        <td id=\"T_a3568_row12_col3\" class=\"data row12 col3\" >0.000000</td>\n",
       "                        <td id=\"T_a3568_row12_col4\" class=\"data row12 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28f4c1ee970>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results_df\n",
    " .style\n",
    " .hide_index()\n",
    " .bar(color='lightblue', vmin=0, subset=['wasserstein_X'], align='zero')\n",
    " .bar(color='lightblue', vmin=0, subset=['wasserstein_y'], align='zero')\n",
    " .bar(color='red', vmin=0, vmax=0.1, subset=['outlier_percent_X'], align='zero')\n",
    " .bar(color='red', vmin=0, vmax=0.1, subset=['outlier_percent_y'], align='zero')\n",
    " .set_caption('Performance Monitoring'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In a typical deployment scenario we would not have access to the true labels so we would not be able to calculate the wasserstein distance between known and predicted targets (shown in the 3rd column).  We would however be able to check for outliers on the targets.  We see that the distance metrics do a very good job detecting the drift in target distribution, the test that is the most important is of course most important at the level of X, because these data will be available.  This example has an additional benefit in that it demonstrates a way to guide the setting of thresholds for throwing flags.  We used bootstrapped data so in reality any outliers that were detected were part of the normal distributional variance.  This implies that a strict threshold could be put at 5% and a more permissive threshold would be closer to 10%.  One final note to keep in mind is that when dealing with data that have many features it is a reasonable practice to reduce the dimensionality of the feature space with PCA before calculating distance and detecting outliers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}